{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DefaultLangchainUserAgent'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_user_agent() -> str:\n",
    "    \"\"\"Get user agent from environment variable.\"\"\"\n",
    "    env_user_agent = os.environ.get(\"USER_AGENT\")\n",
    "    if not env_user_agent:\n",
    "        log.warning(\n",
    "            \"USER_AGENT environment variable not set, \"\n",
    "            \"consider setting it to identify your requests.\"\n",
    "        )\n",
    "        return \"DefaultLangchainUserAgent\"\n",
    "    return env_user_agent\n",
    "\n",
    "get_user_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.2-90b-vision-preview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.tools import StructuredTool, ToolException\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# Tavily search\n",
    "tavily_search_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, urls: List[str]):\n",
    "        self.urls = urls\n",
    "\n",
    "    def scrape_webpages(self) -> str:\n",
    "        \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "        try:\n",
    "            loader = WebBaseLoader(self.urls)\n",
    "            docs = loader.load()\n",
    "            return \"\\n\\n\".join(\n",
    "                [\n",
    "                    f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "                    for doc in docs\n",
    "                ]\n",
    "            )\n",
    "        except ToolException as e:\n",
    "            return self._handle_error(e)\n",
    "\n",
    "    def _handle_error(self, error: ToolException) -> str:\n",
    "        return f\"The following errors occurred during tool execution: `{error.args[0]}`\"\n",
    "\n",
    "web_scraper_tool = StructuredTool.from_function(\n",
    "    func=WebScraper.scrape_webpages,\n",
    "    handle_tool_error=WebScraper._handle_error\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "import nbformat\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The Python code to execute to generate visualization.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code.\"\"\"\n",
    "    try:\n",
    "\n",
    "        result = repl.run(code)\n",
    "    except ToolException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "\n",
    "\n",
    "repl_tool = StructuredTool.from_function(\n",
    "    func=python_repl,\n",
    ")\n",
    "\n",
    "\n",
    "def extract_code_from_response(response: str) -> str:\n",
    "    start = response.find('```python') + len('```python')\n",
    "    end = response.find('```', start)\n",
    "    return response[start:end].strip()\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "tools = [tavily_search_tool, web_scraper_tool, repl_tool]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vwwn', 'function': {'arguments': '{\"code\": \"import matplotlib.pyplot as plt\\\\nimport random\\\\n\\\\nlabels = [\\'A\\', \\'B\\', \\'C\\', \\'D\\', \\'E\\']\\\\nvalues = [random.randint(1, 100) for _ in range(5)]\\\\n\\\\nplt.pie(values, labels=labels)\\\\nplt.show()\"}', 'name': 'python_repl'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 835, 'total_tokens': 912, 'completion_time': 0.449477365, 'prompt_time': 0.074625543, 'queue_time': -0.471637918, 'total_time': 0.524102908}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_9c2a937c92', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4cc2f669-188b-4f28-8704-c3189477306b-0', tool_calls=[{'name': 'python_repl', 'args': {'code': \"import matplotlib.pyplot as plt\\nimport random\\n\\nlabels = ['A', 'B', 'C', 'D', 'E']\\nvalues = [random.randint(1, 100) for _ in range(5)]\\n\\nplt.pie(values, labels=labels)\\nplt.show()\"}, 'id': 'call_vwwn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 835, 'output_tokens': 77, 'total_tokens': 912})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke('Generate a pie chart with random values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: It seems like you didn't ask a question or provide any information. If you need assistance, feel free to ask, and I'll do my best to help.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
