{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_cloud_ops import qdrant_retriever\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model='llama-3.2-90b-vision-preview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self query retriever test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'pdf_id': 'san.pdf', '_id': '640e0756-856c-4c68-9ce2-1d148ee02faa', '_collection_name': 'aireas-cloud'}, page_content='Hinge loss\\nSaturating loss\\nNon-saturating loss\\nGAN\\nSAN\\nGAN\\nSAN\\nGAN\\nSAN\\nCIFAR10\\n24.07±0.56\\n20.23±0.86\\n25.63±0.98\\n20.62±0.94\\n24.90±0.21\\n20.51±0.36\\nCelebA\\n32.51±2.53\\n27.79±1.60\\n37.33±1.02\\n28.16±1.60\\n28.22±2.16\\n27.78±4.59\\nTable 4: FID and IS results with the experimental setup of BigGAN (Brock et al., 2019). Scores\\nmarked with ∗are results from our implementation, which is based on the BigGAN authors’ PyTorch\\nimplementation. For reference, scores reported in their paper are denoted with †.\\nMetric\\nCIFAR10\\nCIFAR100\\nHinge GAN†\\nHinge GAN∗\\nHinge SAN∗\\nHinge GAN∗\\nHinge SAN∗\\nFID (↓)\\n14.73\\n8.25±0.82\\n6.20±0.27\\n10.73±0.16\\n8.05±0.04\\nIS (↑)\\n9.22\\n9.05±0.05\\n9.16±0.08\\n10.56±0.01\\n10.72±0.05\\nTable 5: Numerical results for StyleGAN-XL (Sauer et al., 2022) and StyleSAN-XL. Scores marked\\nwith † and ‡ are reported in their paper and repository, respectively. Note that our StyleSAN-XL\\nmodel trained on CIFAR10 is larger in model size than StyleGAN-XL.\\nMethod\\nCIFAR10\\nImageNet (256×256)\\nStyleGAN-XL‡\\nStyleSAN-XL∗\\nStyleGAN-XL†\\nStyleSAN-XL∗\\nFID (↓)\\n(1.85)\\n1.36\\n2.30\\n2.14\\nIS (↑)\\n–\\n–\\n265.12\\n274.20\\nWe compare SAN and GAN with various objectives. As shown in Fig. 5, the generator measures\\ntrained with SAN cover all modes, whereas mode collapse (Srivastava et al., 2017) occurs with hinge\\nGAN and non-saturating GAN. In addition, Fig. 6 shows a plot of the inner product of the learned\\ndirection ω (or the normalized weight in GAN’s last linear layer) and the estimated optimal direction\\nfor ˜µrJ\\n0\\nand ˜µrJ\\nθ . Recall that there is no guarantee that a non-optimal direction ω induces a distance.\\n7.2\\nIMAGE GENERATION\\nWe apply the SAN scheme to image generation tasks to show it scales beyond toy experiments.\\nDCGAN. We train SANs and GANs with various objective functions on CIFAR10 (Krizhevsky\\net al., 2009) and CelebA (128×128) (Liu et al., 2015). We adopt the DCGAN architectures (Radford\\net al., 2016), and for the discriminator, we apply spectral normalization (Miyato et al., 2018). As\\nshown in Table 3, SANs outperform GANs in terms of the FID score in all cases.'),\n",
       " Document(metadata={'pdf_id': 'san.pdf', '_id': '4c9a4d28-b99a-446f-bd6f-a40794683520', '_collection_name': 'aireas-cloud'}, page_content='⊆\\nL∞(X, RD), we define a family of FMs∗as\\nDFM*\\nF\\n:= {(µ, ν) 7→∥dh(µ, ν)∥2|h ∈F(X)} .\\n(10)\\nFurther, we denote an instance in the family as FM∗\\nh(µ, ν) ∈DFM*\\nF\\n, where h ∈F(X).\\nWe are interested in Question 3.4, which is a mathematical formulation of Question 1.2. We give\\nan answer to this question in Sec. 4. Since optimization of the FM∗is related to JW in Sec. 3.2, the\\nconditions in Question 3.4 enable us to derive (JW, FM∗\\nh)-metrizable conditions in Sec. 5.\\nQuestion 3.4. Under what conditions for F(X) ∈L∞(X, RD) are FM∗\\nh(·, ·) ∈DFM*\\nF\\ndistances?\\n3.2\\nDIRECTION OPTIMALITY TO CONNECT FM∗AND JW\\nOptimization of the FM∗with a given h ∈L∞(X, RD) returns us to an optimization problem\\ninvolving JW.\\nProposition 3.5 (Direction optimality connects FM∗and JW).\\nLet ω be on SD−1.\\nFor\\nany h\\n∈\\nL∞(X, RD),\\nminimization of FM∗\\nh(µθ, µ0) is equivalent to optimization of\\nminθ∈RDθ maxω∈SD−1 JW(θ; ⟨ω, h⟩). Thus, ∇θFM∗\\nh(µθ, µ0) = ∇θJW(θ; ⟨ω∗, h⟩), where ω∗is\\nthe optimal solution (direction) given as follows:\\nω∗= arg max\\nω∈SD−1 d⟨ω,h⟩(µ0, µθ).\\n(11)\\n4\\nPublished as a conference paper at ICLR 2024\\n...\\nCumulrative density functions\\nProbability density functions\\nProjection onto      with\\nFigure 1:\\nDiscriminator decomposition into inner-\\nproduct form ⟨ω, h(x)⟩. Direction ω projects h(x) onto\\nR. In this figure, h is separable because F h,ω∗\\nµ0\\n(ξ) ≤\\nF h,ω∗\\nµθ\\n(ξ) for all ξ ∈R (see Definition 4.2).\\nWasserstein distance\\nEvery \\nis a distance\\n[Proposition 4.5]\\n[Lemma 5.1]\\n[Theorem 5.3]\\n[Lemma 5.2]\\nw/ optimal\\n(Main theorem)\\n[Lemma 4.3]\\nEvery                                           is a distance\\n[Lemma 4.4]\\nFigure 2: Outline of Sec. 4. Proposi-\\ntion 4.5 is a major step toward our main\\ntheorem.\\nThe proof can be found in Appx. D, where the key idea involves using the Cauchy-Schwartz in-\\nequality, ∥dh(µ0, µθ)∥2 ≥⟨ω, dh(µ0, µθ)⟩with ω ∈SD−1, and the linearity of dh(µ0, µθ), leading\\nto ∥dh(µ0, µθ)∥2 ≥d⟨ω,h⟩(µ0, µθ).\\nRecall that we formulated the discriminator in the inner-product form (2), which is aligned with'),\n",
       " Document(metadata={'pdf_id': 'san.pdf', '_id': 'c74c1b34-6eaf-45e1-9950-8eff26b026b0', '_collection_name': 'aireas-cloud'}, page_content='6\\nSLICING ADVERSARIAL NETWORK\\nThis section describes our proposed model, the Slicing Adversarial Network (SAN) to achieve the\\ndirection optimality of ω in Theorem 5.3 while keeping separability of h. We develop SAN by\\nmodifying the maximization problem V to guarantee that the optimal solution ω achieves direction\\noptimality. The proposed modification scheme is applicable to most existing GAN objectives and\\ndoes not necessitate additional exhaustive hyperparameter tuning or computational complexity.\\nAs mentioned in Sec. 5, given a function h, the maximization problems in most GANs (exclud-\\ning Wasserstein GAN) cannot achieve direction optimality with the maximum solution of V (see\\nTable 1). We use hinge GAN as an example to illustrate this claim. The objective function to be\\nmaximized in hinge GAN is formulated as\\nVHinge(⟨ω, h⟩; µθ) := Ex∼µ0[min(0, −1 + ⟨ω, h(x)⟩)] + Ex∼µθ[min(0, −1 −⟨ω, h(x)⟩)].\\n(14)\\nGiven h, the maximizer ω becomes ˆdh(µtr\\n0, µtr\\nθ), where µtr\\n0 and µtr\\nθ denote truncated distributions\\nwhose supports are restricted by conditioning x on ⟨ω, h(x)⟩< 1 and ⟨ω, h(x)⟩> −1, respectively.\\nSince (µtr\\n0, µtr\\nθ) is generally different from (˜µrJ\\n0 , ˜µrJ\\nθ ) = (µ0, µθ), the maximum solution does not\\nsatisfy direction optimality for ˜µrJ\\n0\\nand ˜µrJ\\nθ .\\nIn line with the above discussion, we propose the following novel maximization problem:\\nmax\\nω∈Sd−1,h∈F(X) VSAN(ω, h; µθ) := V(⟨ω−, h⟩; µθ)\\n|\\n{z\\n}\\nLh(h;ω,µθ)\\n+λ · d⟨ω,h−⟩(˜µrJ ◦f\\n0\\n, ˜µrJ ◦f\\nθ\\n)\\n|\\n{z\\n}\\nLω(ω;h,µθ)\\n,\\n(15)\\nwhere (·)−indicates a stop-gradient operator. The first and second terms induce separability on h\\nand direction optimality on ω, respectively. We simply set λ ∈R+ to 1 in our experiments. The\\nproposed modification scheme in Eq. (15) enables us to select any maximization objective for h with\\n7\\nPublished as a conference paper at ICLR 2024\\nTable 2: Minimization problem and weighting function for direction optimization.\\nMinimization problem J\\nWeighting rJ ◦f(x)\\nWasserstein GAN / Hinge GAN\\n−Ex∼µθ [f(x)]\\n1\\nSaturating GAN\\n−Ex∼µθ [log ς(f(x))]\\n1 −ς(f(x))\\nNon-saturating GAN\\nEx∼µθ [log ς(1 −f(x))]'),\n",
       " Document(metadata={'pdf_id': 'san.pdf', '_id': 'b3df32c7-b0c2-4302-9de1-46b9ba5d34a4', '_collection_name': 'aireas-cloud'}, page_content='wasserstein generative models. In Proc. International Conference on Machine Learning (ICML),\\nvolume 139, pp. 6275–6285, 2021.\\nJerry Li, Aleksander Madry, John Peebles, and Ludwig Schmidt. On the limitations of first-order\\napproximation in gan dynamics. In Proc. International Conference on Machine Learning (ICML),\\npp. 3005–3013, 2018.\\nJae Hyun Lim and Jong Chul Ye. Geometric gan. arXiv preprint arXiv:1705.02894, 2017.\\nZinan Lin, Vyas Sekar, and Giulia Fanti. Why spectral normalization stabilizes GANs: Analysis\\nand improvements.\\nIn Proc. Advances in Neural Information Processing Systems (NeurIPS),\\nvolume 34, pp. 9625–9638, 2021.\\nZiwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.\\nIn Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3730–3738,\\n2015.\\nLars Mescheder, Sebastian Nowozin, and Andreas Geiger. The numerics of gans. In Proc. Advances\\nin Neural Information Processing Systems (NeurIPS), volume 30, 2017.\\nLars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for GANs do\\nactually converge? In Proc. International Conference on Machine Learning (ICML), pp. 3481–\\n3490, 2018.\\n12\\nPublished as a conference paper at ICLR 2024\\nPaul Milgrom and Ilya Segal. Envelope theorems for arbitrary choice sets. Econometrica, 70(2):\\n583–601, 2002.\\nTakeru Miyato and Masanori Koyama. cgans with projection discriminator. In Proc. International\\nConference on Learning Representation (ICLR), 2018.\\nTakeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for\\ngenerative adversarial networks. In Proc. International Conference on Learning Representation\\n(ICLR), 2018.\\nAlfred M¨uller. Integral probability metrics and their generating classes of functions. Advances in\\nApplied Probability, 29(2):429–443, 1997.\\nVaishnavh Nagarajan and J Zico Kolter. Gradient descent GAN optimization is locally stable. In\\nProc. Advances in Neural Information Processing Systems (NeurIPS), volume 30, 2017.\\nFrank Natterer. The mathematics of computerized tomography. SIAM, 2001.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_retriever.invoke('what is the coclusion of san.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decomposition chain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the abstract of m.pdf?',\n",
       " 'What are the key points of the transformer model that can be explained in simple terms to a child?',\n",
       " 'What are the recent updates or advancements in the transformer model in the field of artificial intelligence?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chains import create_decomposition_chain\n",
    "\n",
    "dec = create_decomposition_chain(llm=llm)\n",
    "\n",
    "\n",
    "dec.invoke('what is the abstract of m.pdf, what are the recent updates on transformer, explain all this to a child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
